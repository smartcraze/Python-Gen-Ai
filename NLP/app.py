from nltk.tokenize import sent_tokenize, word_tokenize
s= '''
hey this is suraj.
'''
tokenizor = word_tokenize(s)
print(tokenizor)


